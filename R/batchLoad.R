#' @include Models.R
#' @include featuresDefaultLoader.R

#' @title Load the \code{\link{Models}} Generated by
#'   \code{\link{regressoR.batchLearn}}
#' @description Load all the setup results built by
#'   \code{\link{regressoR.batchLearn}} from a folder structure.
#' @param source the source folder
#' @param selector the selector for the files
#' @param featuresFolder the folder where to look for feature information,
#'   \code{NULL} if no feature information is needed
#' @param featuresLoader a function accepting two parameters,
#'   \code{featureFolder} and \code{components} and returning a named list of
#'   features, or \code{NULL} if no features are needed. see
#'   \code{\link{features.defaultLoader}} for documentation
#' @param nameProcessor a function which receives a relativized path to the
#'   folder with the current model(s) and returns a name for the models
#' @param check.directory a function which can choose if a directory should be
#'   followed or not
#' @param cores the number of cores to be used for loading
#' @param logging should progress information be printed: either \code{TRUE} for
#'   printing to the console via \code{\link{print}}, \code{FALSE} for no
#'   logging, or a path to a file receiving logging information
#' @return a list of \code{\link{RegressionResults}} instances
#' @importFrom utilizeR path.batchApply path.extensionRegExp makeLogger
#' @importFrom regressoR regressoR.loadResult
#' @importFrom utilizeR path.relativize
#' @export processMineR.batchLoad
processMineR.batchLoad <- function(source=getwd(),
                              selector=path.extensionRegExp(extensions="model", before.extension="_single"),
                              featuresFolder=file.path(source, "../features"),
                              featuresLoader=features.defaultLoader,
                              nameProcessor=identity,
                              check.directory=NULL,
                              cores=1L,
                              logging=(cores <= 1L)) {

  source <- force(source);
  source <- normalizePath(source);
  source <- force(source);

  # force and canonicalize the features loading process
  featuresFolder <- force(featuresFolder);
  featuresLoader <- force(featuresLoader);
  if(is.null(featuresLoader)) {
    featuresFolder <- NULL;
  } else {
    if(is.null(featuresFolder)) {
      featuresLoader <- NULL;
    } else {
      featuresFolder <- normalizePath(featuresFolder, mustWork=TRUE);
    }
  }

  # first we make the logger function useable
  logging <- makeLogger(logging, cores);
  logging <- force(logging);
  if(!is.null(logging)) {
    ftxt <- if(is.null(featuresFolder)) " without features."
            else paste(" with features from folder ", featuresFolder, ".",
                       sep="", collapse="")
    logging("now loading learned models from ", source, ftxt);
  }

  nameProcessor <- force(nameProcessor);
  check.directory <- force(check.directory);
  cores <- force(cores);

  # build the internal loader function
  loader <- function(root, paths) {
    root <- force(root);
    paths <- force(paths);
    nameProcessor <- force(nameProcessor);
    featuresFolder <- force(featuresFolder);
    featuresLoader <- force(features.defaultLoader);

    # first, for each path load a result record
    results <- unname(unlist(lapply(X=paths, FUN=function(path) {
      # we only load records from files of non-zero size, because there might be
      # some zero-sized files remaining either from crashed or still pending
      # batch learning jobs
      if(file.exists(path) && (file.size(path) > 0L)) {
        return(regressoR.loadResult(path));
      } else {
        # ok, file is empty, no result
        return(NULL);
      }
    }), recursive=TRUE));

    # if there are no results for any of the files, let's simply stop here
    if(is.null(results) || (length(results) <= 0L)) {
      return(NULL);
    }

    # first we extract the name part from the directory
    name <- path.relativize(dirname(paths[1L]), root);

    # now: de we need to apply the features loader
    if(!(is.null(featuresFolder) || is.null(featuresLoader))) {
      # yes, so first split the name
      components <- unname(unlist(strsplit(name, "/"), recursive = TRUE));
      features <- featuresLoader(featuresFolder, components);
    } else {
      features <- list();
    }

    # ok, we have results, so now we need to create the name
    name <- nameProcessor(name);
    if(is.null(names) || (nchar(name) <= 0L)) {
      names <- "unnamed"; # if there are no names, use "unnamed"
    }

    # create and return the results record
    result <- Models.new(name=name, features=features, models=results);
    result <- force(result);
    return(result);
  }
  loader <- force(loader);

  # we now have a loader function ready
  # assign the loader to the regular expression for processors
  file.all <- new.env();
  assign(x=selector, value=loader, envir=file.all);
  file.all <- force(file.all);

  # execute the batch process
  results <- path.batchApply(path=source, file.single=NULL, file.in.folder=file.all,
                             cores=cores, check.directory=check.directory,
                             logging=logging);

  # consolidate the result
  results <- unname(unlist(results, recursive = TRUE));

  if(!(is.null(logging))) {
    # print the status message
    logging("finished loading models fitted to ", length(results), " setups.")
  }

  # canonicalize the result
  if(is.null(results) || (length(results) <= 0L)) {
    return(NULL);
  }

  return(results);
}
